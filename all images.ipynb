{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import winsound\n",
    "\n",
    "frequency = 2500\n",
    "duration = 1000\n",
    "\n",
    "def eyeAspectRatio(eye):\n",
    "    A = cv2.norm(eye[1] - eye[5])\n",
    "    B = cv2.norm(eye[2] - eye[4])\n",
    "    C = cv2.norm(eye[0] - eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def mouthAspectRatio(mouth):\n",
    "    A = cv2.norm(mouth[1] - mouth[7])\n",
    "    B = cv2.norm(mouth[2] - mouth[6])\n",
    "    C = cv2.norm(mouth[0] - mouth[4])\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "    return mar\n",
    "\n",
    "earThresh = 0.3  # Distance between vertical eye coordinate threshold\n",
    "marThresh = 0.3  # Threshold for mouth aspect ratio indicating yawning\n",
    "\n",
    "# Path to the shape predictor file\n",
    "shapePredictor = \"C:\\\\Users\\\\dhana\\\\OneDrive\\\\Desktop\\\\shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# Load the facial landmarks predictor\n",
    "predictor = dlib.shape_predictor(shapePredictor)\n",
    "\n",
    "# Create a face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Indices for left and right eyes\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "(mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "\n",
    "# Path to your dataset directory\n",
    "dataset_path = \"C:\\\\Users\\\\dhana\\\\OneDrive\\\\Desktop\\\\images_folder\"\n",
    "\n",
    "# Loop through images in the dataset directory\n",
    "for filename in os.listdir(dataset_path):\n",
    "    # Read the image\n",
    "    image_path = os.path.join(dataset_path, filename)\n",
    "    frame = cv2.imread(image_path)\n",
    "    \n",
    "    # Check if the image is successfully loaded\n",
    "    if frame is None:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Perform resizing for better processing\n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Use the face detector to identify faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    for rect in rects:\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        leftEAR = eyeAspectRatio(leftEye)\n",
    "        rightEAR = eyeAspectRatio(rightEye)\n",
    "    \n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "        \n",
    "        mouth = shape[mStart:mEnd]\n",
    "        mar = mouthAspectRatio(mouth)\n",
    "    \n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 0, 255), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 0, 255), 1)\n",
    "        \n",
    "        mouthHull = cv2.convexHull(mouth)\n",
    "        cv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
    "    \n",
    "        if ear < earThresh:\n",
    "            cv2.putText(frame, \"EYES BLINKED\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            winsound.Beep(frequency, duration)\n",
    "        \n",
    "        if mar > marThresh:\n",
    "            cv2.putText(frame, \"YAWNING DETECTED\", (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            winsound.Beep(frequency, duration)\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "\n",
    "frequency = 2500\n",
    "duration = 1000\n",
    "\n",
    "def eyeAspectRatio(eye):\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def mouthAspectRatio(mouth):\n",
    "    A = np.linalg.norm(mouth[2] - mouth[10])\n",
    "    B = np.linalg.norm(mouth[4] - mouth[8])\n",
    "    C = np.linalg.norm(mouth[0] - mouth[6])\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "    return mar\n",
    "\n",
    "class DetectionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detection App\")\n",
    "\n",
    "        self.image_path = None\n",
    "        self.eye_blinking_results = []\n",
    "        self.yawning_results = []\n",
    "\n",
    "        self.label = tk.Label(root, text=\"Detection App\", font=(\"Helvetica\", 16))\n",
    "        self.label.pack(pady=10)\n",
    "\n",
    "        self.load_button = tk.Button(root, text=\"Load Image\", command=self.load_image)\n",
    "        self.load_button.pack(pady=10)\n",
    "\n",
    "        self.detect_eye_blinking_button = tk.Button(root, text=\"Detect Eye Blinking\", command=self.detect_eye_blinking)\n",
    "        self.detect_eye_blinking_button.pack(pady=5)\n",
    "\n",
    "        self.detect_yawning_button = tk.Button(root, text=\"Detect Yawning\", command=self.detect_yawning)\n",
    "        self.detect_yawning_button.pack(pady=5)\n",
    "\n",
    "        self.canvas = tk.Canvas(root, width=500, height=400)\n",
    "        self.canvas.pack()\n",
    "\n",
    "    def load_image(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"C:\\\\Users\\\\dhana\\\\OneDrive\\\\Desktop\\\\images_folder\", \"*.jpg;*.png;*.jpeg\")])\n",
    "        if file_path:\n",
    "            self.image_path = file_path\n",
    "            self.display_image()\n",
    "\n",
    "    def detect_eye_blinking(self):\n",
    "        if self.image_path:\n",
    "            frame = cv2.imread(self.image_path)\n",
    "            if frame is not None:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                rects = detector(gray, 0)\n",
    "                eye_blinking_detected = False\n",
    "\n",
    "                for rect in rects:\n",
    "                    shape = predictor(gray, rect)\n",
    "                    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "                    leftEye = shape[36:42]\n",
    "                    rightEye = shape[42:48]\n",
    "\n",
    "                    leftEAR = eyeAspectRatio(leftEye)\n",
    "                    rightEAR = eyeAspectRatio(rightEye)\n",
    "\n",
    "                    ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "                    if ear < 0.2:  # Example threshold for eye blinking\n",
    "                        eye_blinking_detected = True\n",
    "                        break\n",
    "\n",
    "                self.eye_blinking_results.append(eye_blinking_detected)\n",
    "                print(\"Eye Blinking Detected:\", eye_blinking_detected)\n",
    "\n",
    "    def detect_yawning(self):\n",
    "        if self.image_path:\n",
    "            frame = cv2.imread(self.image_path)\n",
    "            if frame is not None:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                rects = detector(gray, 0)\n",
    "                yawning_detected = False\n",
    "\n",
    "                for rect in rects:\n",
    "                    shape = predictor(gray, rect)\n",
    "                    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "                    mouth = shape[48:68]\n",
    "                    mar = mouthAspectRatio(mouth)\n",
    "\n",
    "                    if mar < 0.4:  # Example threshold for yawning\n",
    "                        yawning_detected = True\n",
    "                        break\n",
    "\n",
    "                self.yawning_results.append(yawning_detected)\n",
    "                print(\"Yawning Detected:\", yawning_detected)\n",
    "\n",
    "    def display_image(self):\n",
    "        if self.image_path:\n",
    "            img = Image.open(self.image_path)\n",
    "            img = img.resize((500, 400), Image.ANTIALIAS)\n",
    "            img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "            self.canvas.config(width=img_tk.width(), height=img_tk.height())\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=img_tk)\n",
    "            self.canvas.image = img_tk\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dist = __import__(\"scipy.spatial.distance\").distance\n",
    "    shape_predictor_path =  \"C:\\\\Users\\\\dhana\\\\OneDrive\\\\Desktop\\\\shape_predictor_68_face_landmarks.dat\"\n",
    "    predictor = dlib.shape_predictor(shape_predictor_path)\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    root = tk.Tk()\n",
    "    app = DetectionApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf2de1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
